---
title:  "Pyspark 설치하기"
excerpt : "pyspark를 설치한다."

categories:
  - PySpark 
tags:
  - 

toc: true
toc_sticky: true
 
date: 2022-04-22
last_modified_at: 2022-04-24
---

# PySpark 설치

- pyspark를 설치한다
    - 사전에 파이썬3 가 설치되어잇으면된다.
    - 앞전에 java 설치를 다루었기에 java 설치를 제외한다.
    - 

- Spark 설치
    - 설치 주소:**[https://www.apache.org/dyn/closer.lua/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz](https://www.apache.org/dyn/closer.lua/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz)**
    - 위에 버전은 3.2 버전이다 버전을 잘 기억하기바란다.
    - 아래 화면에서 The object is in our archive : [https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz](https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz) 를 클릭한다.
    
   ![Untitled](https://user-images.githubusercontent.com/101306770/164963041-f0194975-9ad2-428d-ab3d-8fd63596784f.png)
    
- WinRAR 프로그램 다운로드
    - 해당 프로그램은 위에서 받은 tgz 파일 압축 해제기이다.
    - **[https://www.rarlab.com/download.htm](https://www.rarlab.com/download.htm)**
    - 각 pc 에 맞는 파일을 설치한다.
    - 나는 64bit 기에 맨 위에 파일을 받았다.
    
    ![Untitled 1](https://user-images.githubusercontent.com/101306770/164963383-47b25d27-bb64-47e8-97fa-429997f723b2.png)
    
- spark 폴더 생성 및 파일이동
    - winrar을 받은 후에 spark.tgz 파일을 압축 해제한다.
    - 압축 해제후 spark-3.2.0-bin-hadoop3.2 폴더를 복사한다.
    - 복사 후에 C 드라이브로 옮긴 후 해당 폴더의 이름을 spark 로 변경해준다.
    - 
    
    ![Untitled 2](https://user-images.githubusercontent.com/101306770/164963496-b76f0860-134f-4b83-9222-32c920fdf6e9.png)
    

- ****log4j.properties 파일 수정****
    - spark 안에있는 폴더중 conf 파일안에 ****log4j.properties을 연다.****
    - 해당 파일은 메모장으로 열어 확인해도된다.
    - 확인시 아래와 같은 화면이 나올것이다.
    - 
    
   ![Untitled 3](https://user-images.githubusercontent.com/101306770/164963606-5f3180ee-3004-47a5-959b-51b9cdb488b8.png)
    - 위에 화면이 나오면 메모장으로 열되 항상 이앱을~~이라는 문구에 되어있는 체크박스는 해제한다.
    - 아래와 같은 화면에서 log4j.rootCategory=INFO, console → log4j.rootCategory=ERROR, console 로 변경해준다.
    
    ![Untitled 4](https://user-images.githubusercontent.com/101306770/164964570-c67f7c65-f455-4d76-8412-588688d80b97.png)
    - 저장 후 완료하게 되면 된다.
- winutils 설치
    - winutils 파일을 설치한다.
    - 설치파일: **[https://github.com/cdarlint/winutils](https://github.com/cdarlint/winutils)**
    - 위 url 에서  Spark 와 같은 버전의 winutils 를 다운받는다.
    - 다운 후 C드라이브에 winutils 폴더 생성, 해당폴더안에 bin 폴더를 생성해준다.
    - 이 파일이 Spark 실행 시, 오류 없이 실행될 수 있도록 파일 사용 권한을 얻도록 한다
        - cmd 관리자  권한으로 파일을 실행한다.
        - 만약, ChangeFileModeByMask error (3) 에러 발생 시, C드라이브 하단에, `tmp\hive` 폴더를 차례대로 생성을 한다.
    
    ```
    C:\Windows\system32>cd c:\winutils\bin
    c:\winutils\bin> winutils.exe chmod 777 \tmp\hive
    ```
    

- 환경변수 설정
    - 앞서 JAVA의 환경변수 설정과 비슷하다.
        - SPARK_HOME 환경변수를 설정한다.
        
        !![Untitled 5](https://user-images.githubusercontent.com/101306770/164963831-9bd60736-2758-401b-8231-ce3df2681b85.png)
        
        - • HADOOP_HOME 환경변수를 설정한다.
        
        ![Untitled 6](https://user-images.githubusercontent.com/101306770/164963921-88a612ea-610f-486e-876b-240521def461.png)
        
    - 이번에는 `PATH` 변수를 편집한다. 아래코드를 추가한다.
        - %SPARK_HOME%\bin
        
- 파이썬 환경설정
    - • Python 환경설정을 추가한다.
        
        ![Untitled 7](https://user-images.githubusercontent.com/101306770/164964018-e71694d3-3126-4e36-846d-9ea900ea49b2.png)
        
- Spark 테스트
    - CMD 파일을 열고 `c:\spark` 폴더로 경로를 설정 한다. (이때는 관리자권한으로 설정으로 진행하지 않는다.)
    - 아래 화면이 나올 것이다.
    
    ![Untitled 8](https://user-images.githubusercontent.com/101306770/164964219-7aead3d9-c610-42a6-b654-0c7991d1222b.png)
    

• 이번에는 해당 `[README.md](http://README.md)` 파일을 불러와서 아래 코드가 실행되는지 확인한다.

![Untitled 9](https://user-images.githubusercontent.com/101306770/164964628-9a539583-56a6-4ce5-925f-8d956ed68734.png)

- 위와 같은 화면이 나온다면 성공이다.
- 참조 [https://dschloe.github.io/python/python_edu/00_settings/spark_installation_windows_10/](https://dschloe.github.io/python/python_edu/00_settings/spark_installation_windows_10/)